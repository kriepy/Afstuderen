\documentclass[11pt,a4paper]{report}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\begin{document}

%----------------------------------INTRODUCTION--------------------------------------------
\section{Introduction}

Why is activity recognition done?? What is it used for?
Monitor elderly? To check if they do their daily routine normally. That there are no abnormal behaviours like setting coffee 10 time in an hour.  So mentally and physical fit. Also giving an alarm in dangerous situations?

Activity recognition is hard. Finding the excact activity from sensor data can be difficult for different reasons:
- fuzzy timelength, it is not always clear when an activity starts or ends.
- activities can be done in different ways. Making koffie: first water or first filter?
A couple of difficults are described in [phd Tim] More??

Another problem is that many activity recognition models are based on labeled data. Labeling is timeconsuming and also effects the behaviour of the people while doing the labeling.

For these reasons we want to find another way to describe the behaviour of people in their house environment using an unsubervised method. We do not focus so much on the exact activities but more on the global behaviour during a day.



%--------------------------------METHOD:LDA-----------------------------------------------
\part{LDA}
\section{Topicmodel for daily behaviour of people in home enviroments}
!!!Korte omschrijving wat hier wordt vertelt.


\subsection{Data description}
Sensors are placed in the home enviroment of people. The sensors can send the value zero or one. The sensors are placed at different locations in the homes and several sensors are grouped together in a field. A field can be for example the 'kitchen'. All sensors that are placed in the kitchen belongs to this field. The sensors that belong to a field can differ between different houses and are specified manually. In the following descriptions we use five different fields. The fields are \{'kitchen','living','bathroom','bedroom','hallway'\}.
All sensors send to the same receiver and store the time a sensor has changed in seconds. 
A more detailed description of the sensor data can be find in [phd tim]. The measurement for every sensor is done ... how? Is that even important? 



-Wat krijg ik voor data binnen (timesequential data, 1 of 0)
-waar komt die data vandaan
-vijf verschillende huizen precies aangeven hoeveel dagen per huis. er is maar een persoon in huis, leven zelfstandig, maar er kan niet worden uitgesloten of er andere personen op bezoek komen.
Volleidig ongelabeld.
Sensoren zijn ingedeeld in fields (Living, Bathroom, Kitchen, Bedroom, Hallway)

-wat zijn problemen met die data (niet altijd even betrouwbaar, dubbel shots,...)



\subsection{Topic model for time sequential data}
Why do I use topic models? What is the motivation behind it to use it on the data of the data? Given in introduction?

We want to find the behaviour of people and how their live is structured. In [cellphone article] they use a topic model to ... Why are they doing it??
These models are based on document clustering, where a document is a combination of different topics. In our case a topic can be something like 'getting up early' or 'leaving the house in the afternoon'. One day of a persons life than can be described with a combination of all existing topics. It might be possible to group days together like weekend or week days. Or all wednesdays, the day that the person always get visiters for example or is going out. 



In our case we have five fields and we count how often a sensor is triggered in a field. That means that it does not matter which sensor in a field is triggered.




\section{Latent dirichlet allocation with our Data}
In a first step we want to analyse the data. How could we do that? Activity recognition is a big part in this field. But we don't want to now activities. That information is to much detail. To monitor elderly over a long period of time you do not need to see the activities, but you need to recognize differences in their daily behaviour.
Labeling data cost a lot of time and it also falses the data because the labeling task itself influences the daily behaviour patterns. There for we want to find a good representation of a daily behaviours.
Like described in [mobile article] a way to do is to find underlying topics in a description of days.
The problem here is that we have a lot sensors that can be triggered in a infinit amount of times. Length of trigger time is not important.


To find a good representation of the data we need to build features. Therefor we descritize the data. 

To find underlying structures in the data, which means finding habbits in the daily structures of people is the goal.


\subsection{Latent dirichlet allocation with our Data}
The generative model 'Latent Dirichlet Allocation' [is er nog een andere articel die dat omschrijft] is a way to describe a topics model. In this model it is assumed that a Corpus can be generated from a distribution of topics. And every topic is described with a distribution of words.
In our case the Corpus is a set of days and every day is representing a document. For the words that are making the day, in a first approach we seperate a day in timeslices of half an hour. In every half hour we count the amount of times that a sensor is triggered in a field. Like in [cellphone] is described we combine the consecutive timeslices and a coarse grain time value into a word.

Verder korte omschrijving van hoe generative process. Dan zeggen dat EM wordt gebruikt zoals bij Blei omschreven.


-data omzetten om te gebruiken met LDA
-wat zijn de woorden, wat documenten, wat corpus
-short introduction to LDA

\subsection{Preprocessing data with k-means}
In the case of our data the size of the dictionary, which contains all unique words in the whole corpus (in our case a set of consecutive days), is relative large with respect to the size of the data. And in this way the structure of daily behaviour is not captured well.
Therefor we first cluster the data with respect to there amount of sensor views in the fields. So that a measurement in one timeslice looks like this


Can not use previous described data because no good structure. That is why we cluster the words in advance and then use the EM-algorithm to find the values of the model.



\subsection{Uitbreiding LDA algorithme}
Preprocessing the data with k-means may influence the LDA model. To capture the clusters directly in the model we adjusted the LDA approach. 

%---------------------------------------------------METHOD:GENETIC-------------------------------------
\part{Generic Algorithm}
Als de likelihood een maat is dan kan het makkelijk overfitten op deze specifieke data. Dan is het misschien nodig om train, test en validation sets te maken. Hierdoor zul je weinig data hebben en misschien is cross validation ervoor nodig.

%-------------------------------------------RESULTS---------------------------------------
\section{Results}


%---------------------------------DISCUSSION-------------------------------------------------
\section{Discussion}


\end{document}
