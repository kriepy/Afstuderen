\documentclass[11pt,a4paper]{report}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\begin{document}

%----------------------------------INTRODUCTION--------------------------------------------
\section{Introduction}
Mijn verwachtingen van het project waren meer dat het veel practischer en meer toepassingsgericht zou zijn. Ik wil liever iets maken waar mensen iets aan hebben en wat nuttig voor hun kan zijn, dan een theoretische opdracht.
Ik moet een klaar doel voor ogen hebben.


Why is activity recognition done?? What is it used for?
Monitor elderly?

Activity recognition is hard. Finding the excact activity from sensor data can be difficult for different reasons:
- fuzzy timelength, it is not always clear when an activity starts or ends.
- activities can be done in different ways. Making koffie: first water or first filter?
A couple of difficults are described in [phd Tim] More??

Another problem is that many activity recognition models are based on labeled data. Labeling is timeconsuming and also effects the behaviour of the people while doing the labeling.

For these reasons we want to find another way to describe the behaviour of people in their house environment using an unsubervised method.


%--------------------------------METHODs-----------------------------------------------------
\section{Topicmodel for daily behaviour of people in home enviroments}
!!!Korte omschrijving wat hier wordt vertelt.


\subsection{Data description}
Sensors are placed in the home enviroment of people. The sensors can send the value zero or one. The sensors are placed at different locations in the homes and several sensors are grouped together in a field. A field can be for example the 'kitchen'. All sensors that are placed in the kitchen belongs to this field. The sensors that belong to a field can differ between different houses and are specified manually. In the following descriptions we use five different fields. The fields are \{'kitchen','living','bathroom','bedroom','hallway'\}.
The measurement for every sensor is done ... how? All sensors send to the same receiver and give the time value in seconds and if the value of the sensor changed from zero to one or the other way around.
A more detailed description of the sensor data can be find in [phd tim].


-Wat krijg ik voor data binnen
-waar komt die data vandaan
-wat zijn problemen met die data (niet altijd even betrouwbaar, dubbel shots,...)


\subsection{Topic model for time sequential data}
Why do I use topic models? What is the motivation behind it to use it on the data of the data? Given in introduction?

We want to find the behaviour of people and how their live is structured. In [cellphone article] they use a topic model to ... Why are they doing it??
These models are based on document clustering, where a document is a combination of different topics. In our case a topic can be something like 'getting up early' or 'leaving the house in the afternoon'. One day of a persons life than can be described with a combination of all existing topics. It might be possible to group days together like weekend or week days. Or all wednesdays, the day that the person always get visiters for example or is going out. 



In our case we have five fields and we count how often a sensor is triggered in a field. That means that it does not matter which sensor in a field is triggered.



To find underlying structures in the data, which means finding habbits in the daily structures of people is the goal.


\subsection{Latent dirichlet allocation with our Data}
The generative model 'Latent Dirichlet Allocation' [is er nog een andere articel die dat omschrijft] is a way to describe a topics model. In this model it is assumed that a Corpus can be generated from a distribution of topics. And every topic is described with a distribution of words.
In our case the Corpus is a set of days and every day is representing a document. For the words that are making the day, in a first approach we seperate a day in timeslices of half an hour. In every half hour we count the amount of times that a sensor is triggered in a field. Like in [cellphone] is described we combine the consecutive timeslices and a coarse grain time value into a word.

Verder korte omschrijving van hoe generative process. Dan zeggen dat EM wordt gebruikt zoals bij Blei omschreven.


-data omzetten om te gebruiken met LDA
-wat zijn de woorden, wat documenten, wat corpus
-short introduction to LDA

\subsection{Preprocessing data with k-means}
In the case of our data the size of the dictionary, which contains all unique words in the whole corpus (in our case a set of consecutive days), is relative large with respect to the size of the data. And in this way the structure of daily behaviour is not captured well.
Therefor we first cluster the data with respect to there amount of sensor views in the fields. So that a measurement in one timeslice looks like this


Can not use previous described data because no good structure. That is why we cluster the words in advance and then use the EM-algorithm to find the values of the model.



\subsection{Uitbreiding LDA algorithme}
Preprocessing the data with k-means may influence the LDA model. To capture the clusters directly in the model we adjusted the LDA approach. 


%-------------------------------------------RESULTS---------------------------------------
\section{Results}


%---------------------------------DISCUSSION-------------------------------------------------
\section{Discussion}


\end{document}