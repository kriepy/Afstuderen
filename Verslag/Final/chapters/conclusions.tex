%What is done in this thesis?
In this thesis two novel models, LDA-Gaussian and LDA-Poisson, are presented. The models are both successfully applied to real-life, binary  sensor data, which is gathered from five different houses of elderly people. It is shown that the models can find meaningful topics in relative little data.\\

%How can topics be used?
The topics and how these topics are distributed over a day can give a good insight on peoples daily behavior. This information can be used to monitor peoples health condition on a long term basis. Changes in the patterns can be a sign of decline in the health of people. These declines can be detect manually or even automatically.\\

% comparing with BOW+k-means
In the experiments it is shown that a better topic distribution can be found with the new models. LDA with a BOW representation on the other hand is not able to find such rich representations of the data. The new models cannot be compared to the BOW approaches in terms of the log-likelihood.\\

% Wat is wrong with the models?
The experiments show that, when time dimension is not taken into account, the LDA-Poisson model performs better than LDA-Gaussian model. This is an expected outcome, because without the time dimension, the feature representation of all dimension is event based. The Poisson distribution is not appropriate to model the time dimension, because this distribution is not symmetric. The Gaussian distribution is a better fit, but time is periodical and topics that are found during the night might be separated because of the linear representation of the time. The von Mises distribution, which is a continuous probability distribution on a circle, is a potential better choice.\\

%TOTHIER
% Wat can be done in future work with the model?
In future work it might be a good idea to combine different distributions for the different dimensions in the observations. Event based dimensions can be modeled with the Poisson distribution and time can be modeled with the von Mises distribution.
Another idea might be to investigate the LDA-Gaussian model in more detail. In the implementation the covariance is modeled with a diagonal matrix. A fully trained covariance matrix is able to capture relationships between the different dimensions and could lead to better topic descriptions. To be able to find a correct covariance matrix a lot of data needs to be available and this is however contradictory to one main benefits of the new topic models: the fact that it can find topics in relative little data. \\

% Wat is wrong with the feature representation?
In this thesis a simple feature representation was chosen. In the experiments only a variation in size of non-overlapping time-slices was considered. Small time-slices did lead to a higher likelihood on a hold-out-set, but the topics that were found were not informative enough. In addition, smaller slices leaded to a higher complexity of the model. This is not desirable, because of the high computational costs.
There are many other representation that could be used to find good features. For example time-slice can be overlapping each other or a word can be a combination of the values from sequential time-slices, like it is done in the work of Farrahi et al. \cite{farrahi2008daily}. In this way the transitions are taken into account. Other possibilities are: Taking the activation length of a sensor into account or looking at every sensor separately than rather put them together in one field. In fact there are infinite ways to combine the data into features and the best representation is probably not yet found. With a more complex representation the computational costs will raise and even more important the features are more likely to overfit the data.\\

% How can the models help to find the best feature represenation?
Finding the best feature representation is in fact a big challenge. The proposed models give the opportunity to investigate feature representation. For example a Genetic algorithm can be used to investigate the feature space. The likelihood with a combination of a penalty for high complexity can be a good fitness function to automatically find the best feature representation.











